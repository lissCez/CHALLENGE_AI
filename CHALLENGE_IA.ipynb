{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlL2cfK6LoGkzywu2ql1pT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lissCez/CHALLENGE_AI/blob/main/CHALLENGE_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**INTEGRANTES**#\n",
        "##Nome: Melissa Barbosa de Souza - RM: 552535\n",
        "##Nome: Alissa Silva Cezero - RM: 553954\n",
        "##Nome: Nícolas Paiffer do Carmo - RM: 554145"
      ],
      "metadata": {
        "id": "NGLpItV2JZcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Pedimos que não sejam executadas as células abaixo, utilizamos apenas exemplificações, portanto ainda se trata de um rascunho)"
      ],
      "metadata": {
        "id": "4fyTlOooK3o6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, implementamos um modelo de detecção de fraudes usando bibliotecas de Machine Learning, ou seja, **scikit-learn** para algoritmos tradicionais, ou **TensorFlow/Keras** para redes neurais. Preferimos usar o Google Colab, pois fornece um ambiente de programação baseado em nuvem com suporte a GPUs.\n",
        "Abaixo estão as etapas do começo do projeto de **Detecção de Fraudes**."
      ],
      "metadata": {
        "id": "jJ4bt74ZDSc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Preparando o Ambiente e os Dados\n",
        "\n",
        "Como é apenas um rascunho não temos um dataset montado, portanto usamos o **Credit Card Fraud Detection Dataset** do Kaggle que é um bom ponto de partida para simular um cenário de fraudes."
      ],
      "metadata": {
        "id": "-641fZn-IA6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn seaborn matplotlib"
      ],
      "metadata": {
        "id": "3qg3slFAIEj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importando as bibliotecas:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "VeTrOBFjIKZi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Carregamento e Visualização dos Dados\n",
        "\n",
        "Carregando o arquivo CSV:"
      ],
      "metadata": {
        "id": "6hm0YFOQIPn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando dados (subistituiremos o 'fraud_data.csv' pelo caminho do nosso próprio arquivo)\n",
        "data = pd.read_csv('fraud_data.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "wkjmaonkIZzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vizualizando o balanceamento dos dados (geralmente existem poucos casos de fraude, então dados reais serão desbalanceados):"
      ],
      "metadata": {
        "id": "BV5P1lskIhzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"Class\", data=data)\n",
        "plt.title(\"Distribuição de fraudes e transações normais\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HAJGTv67Ir5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Pré-Processamento dos Dados\n",
        "\n",
        "Dividindo as colunas em variáveis dependentes (X) e alvo (y), e fazendo a divisão em conjuntos de treino e teste:"
      ],
      "metadata": {
        "id": "9RqK0cg4IwbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(\"Class\", axis=1)\n",
        "y = data[\"Class\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "JnZ2zLw0IzdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Treinamento do Modelo com **Isolation Forest**\n",
        "\n",
        "O Isolation Forest é ideal para detecção de anomalias, pois detecta pontos fora do padrão (como fraudes).\n",
        "Iremos treiná-lo nos dados."
      ],
      "metadata": {
        "id": "ZwUi_zi6I3m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = IsolationForest(n_estimators=100, max_samples='auto', contamination=float(0.1), random_state=42)\n",
        "model.fit(X_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = [1 if x == -1 else 0 for x in y_pred]"
      ],
      "metadata": {
        "id": "kA2R2KaVI7AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Avaliação do Modelo\n",
        "\n",
        "Utilizamos métricas como matriz de confusão e o relatório de classificação para avaliarmos o desempenho."
      ],
      "metadata": {
        "id": "vWhO_nViI-FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "xqFj6awJJARI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Matriz de Confusão mostra:\n",
        "- Verdadeiros Positivos (fraudes detectadas corretamente),\n",
        "- Falsos Positivos (transações normais marcadas como fraudes),\n",
        "- Verdadeiros Negativos (transações normais detectadas corretamente), e\n",
        "- Falsos Negativos (fraudes não detectadas)."
      ],
      "metadata": {
        "id": "9dQTbbJ-JD5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Visualização dos Resultados\n",
        "\n",
        "Para deixarmos mais claro faremos gráficos que mostram a separação dos casos de fraude e transações normais."
      ],
      "metadata": {
        "id": "EOzMfqODJM_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_test)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred, cmap='coolwarm', label='Detecções')\n",
        "plt.title('Visualização de Detecção de Fraudes')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend(['Normal', 'Fraude'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vPpsRWNQJPlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Melhoria e Ajustes\n",
        "\n",
        "1. **Balanceamento de Dados**: Se o dataset ficar muito desbalanceado, usaremos **SMOTE** (Synthetic Minority Over-sampling Technique) para suavizar esses desbalanceamentos;\n",
        "\n",
        "2. **Escolha de Modelos**: Pretendemos usar outros modelos de \"detecção de anomalias\" como SVMs e talvez redes neurais;\n",
        "\n",
        "3. **Parâmetros de Contaminação**: Também ajustaremos os parâmetros de \"contaminação\" do Isolation Forest para que a taxa de fraudes seja a esperada nos dados."
      ],
      "metadata": {
        "id": "58f46w1GJUPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Concluíndo**\n",
        "\n",
        "Mesmo com essa configuração inicial funcionando bem, vemos várias oportunidades de aprimoramento. Pretendemos explorar técnicas de balanceamento de dados, como o SMOTE, e testar novos modelos de anomalias, incluindo redes neurais, para refinar ainda mais a precisão da detecção. Esse rascunho oferece uma base sólida que facilita futuros ajustes e abre caminho para uma implementação mais completa."
      ],
      "metadata": {
        "id": "fkov1dq3JWIZ"
      }
    }
  ]
}